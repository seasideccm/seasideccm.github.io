(window.webpackJsonp=window.webpackJsonp||[]).push([[130],{875:function(e,t,r){"use strict";r.r(t);var a=r(12),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"five-principles-for-the-intelligent-use-of-ai-in-medical-imaging"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#five-principles-for-the-intelligent-use-of-ai-in-medical-imaging"}},[e._v("#")]),e._v(" Five principles for the intelligent use of AI in medical imaging")]),e._v(" "),r("ul",[r("li",[e._v("[Errol Colak](javascript:üòâ             "),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/http/N73GG4LEF3YYE3D/0000-0002-3771-7975",target:"_blank",rel:"noopener noreferrer"}},[e._v("ORCID: orcid.org/0000-0002-3771-7975"),r("OutboundLink")],1),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#Aff1",target:"_blank",rel:"noopener noreferrer"}},[e._v("1"),r("OutboundLink")],1),e._v(","),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#Aff2",target:"_blank",rel:"noopener noreferrer"}},[e._v("2"),r("OutboundLink")],1),e._v(",")]),e._v(" "),r("li",[e._v("[Robert Moreland](javascript:üòâ             "),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/http/N73GG4LEF3YYE3D/0000-0001-5456-1637",target:"_blank",rel:"noopener noreferrer"}},[e._v("ORCID: orcid.org/0000-0001-5456-1637"),r("OutboundLink")],1),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#Aff3",target:"_blank",rel:"noopener noreferrer"}},[e._v("3"),r("OutboundLink")],1),e._v(","),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#Aff4",target:"_blank",rel:"noopener noreferrer"}},[e._v("4"),r("OutboundLink")],1),e._v(" &")]),e._v(" "),r("li",[e._v("[Marzyeh Ghassemi](javascript:üòâ             "),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/http/N73GG4LEF3YYE3D/0000-0001-6349-7251",target:"_blank",rel:"noopener noreferrer"}},[e._v("ORCID: orcid.org/0000-0001-6349-7251"),r("OutboundLink")],1),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#Aff5",target:"_blank",rel:"noopener noreferrer"}},[e._v("5"),r("OutboundLink")],1),e._v(","),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#Aff6",target:"_blank",rel:"noopener noreferrer"}},[e._v("6"),r("OutboundLink")],1)])]),e._v(" "),r("p",[r("a",{attrs:{href:"http://61.175.198.136:8083/journal/134",target:"_blank",rel:"noopener noreferrer"}},[r("em",[e._v("Intensive Care Medicine")]),r("OutboundLink")],1),e._v(" "),r("strong",[e._v("volume 47")]),e._v(", pages154‚Äì156(2021)"),r("a",{attrs:{href:"http://61.175.198.136:8083/rwt/150/https/NSVX643PPNZHE4LPM7TYELUDN7XB/article/10.1007/s00134-020-06316-8#citeas",target:"_blank",rel:"noopener noreferrer"}},[e._v("Cite this article"),r("OutboundLink")],1)]),e._v(" "),r("ul",[r("li",[e._v("1901 Accesses")]),e._v(" "),r("li",[e._v("21 Altmetric")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8/metrics",target:"_blank",rel:"noopener noreferrer"}},[e._v("Metrics details"),r("OutboundLink")],1)])]),e._v(" "),r("h2",{attrs:{id:"clinical-scenario"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#clinical-scenario"}},[e._v("#")]),e._v(" Clinical scenario")]),e._v(" "),r("p",[e._v("You are a critical care physician at a medium-sized urban hospital. A local start-up is promoting software that claims to automatically interpret chest X-rays. Having read many articles about artificial intelligence, you are intrigued by the idea of using it. However, you have never had to decide if, when, and how to deploy these technologies in clinical practice.")]),e._v(" "),r("h2",{attrs:{id:"background"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#background"}},[e._v("#")]),e._v(" Background")]),e._v(" "),r("p",[e._v("Artificial intelligence (AI) promises to transform healthcare by improving clinical decision-making, reducing errors, and automating tasks ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR1",target:"_blank",rel:"noopener noreferrer"}},[e._v("1"),r("OutboundLink")],1),e._v("]. Recent advances in machine learning (ML), a branch of AI, have demonstrated expert-level task performance including medical image analysis ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR2",target:"_blank",rel:"noopener noreferrer"}},[e._v("2"),r("OutboundLink")],1),e._v("]. With an increasing number of medical imaging ML systems receiving regulatory approval, critical care physicians will have an additional set of tools at their disposal. However, the deployment of these systems into clinical environments can be fraught with pitfalls. This article introduces 5 key principles that should be remembered as the adoption of ML systems becomes more widespread.")]),e._v(" "),r("h3",{attrs:{id:"knowledge-base-ensure-you-have-enough-understanding-of-machine-learning-to-separate-fact-from-fiction-in-vendor-claims"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#knowledge-base-ensure-you-have-enough-understanding-of-machine-learning-to-separate-fact-from-fiction-in-vendor-claims"}},[e._v("#")]),e._v(" Knowledge base: ensure you have enough understanding of machine learning to separate fact from fiction in vendor claims")]),e._v(" "),r("p",[e._v("If physicians are to be integral to the development, adoption, and oversight of ML models, it is paramount for them to develop basic competency in ML. Physicians should become familiar with dataset preparation, model architecture selection, and how statistical methods are applied during model evaluation. Knowledge and skills in ML would empower physicians to understand the potential capabilities and limitations of ML, critically appraise and validate models, and address patient concerns. A deeper understanding of how ML models are created and evaluated may help to determine how model outputs can be best integrated into clinical decision-making. Readers are encouraged to explore the many online educational resources, many free of charge, that are available for self-directed and class-based learning (Supplemental Material).")]),e._v(" "),r("h3",{attrs:{id:"metrics-ensure-that-the-evaluation-metrics-provided-by-the-vendor-are-meaningful-in-clinical-practice-and-not-limited-to-accuracy"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#metrics-ensure-that-the-evaluation-metrics-provided-by-the-vendor-are-meaningful-in-clinical-practice-and-not-limited-to-accuracy"}},[e._v("#")]),e._v(" Metrics: ensure that the evaluation metrics provided by the vendor are meaningful in clinical practice and not limited to accuracy")]),e._v(" "),r("p",[e._v("Model performance is often reported as an accuracy measure or confusion matrix. This is potentially problematic as models may demonstrate reduced accuracy when operating under real-world circumstances ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR3",target:"_blank",rel:"noopener noreferrer"}},[e._v("3"),r("OutboundLink")],1),e._v("]. Furthermore, these metrics fail to consider prevalence, the impact of incorrect recommendations, and may in fact convey a false sense of safety. Determining a model‚Äôs clinical benefit, robustness, direct and indirect costs, calibration, safety profile, interpretability, and user acceptance are much more meaningful forms of evaluation and are unfortunately often not available ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR4",target:"_blank",rel:"noopener noreferrer"}},[e._v("4"),r("OutboundLink")],1),e._v("]. Rather than focusing on the area under the curve, a commonly used metric in the ML literature, the focus needs to be on rigorous clinical validation. The validation process for a novel ML model should be no less rigorous and thorough than that of a new drug or diagnostic test to ensure efficacy, reliability, acceptability, and safety ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR5",target:"_blank",rel:"noopener noreferrer"}},[e._v("5"),r("OutboundLink")],1),e._v("].")]),e._v(" "),r("h3",{attrs:{id:"bias-ensure-the-data-used-for-model-development-by-the-vendor-reflects-the-case-mix-of-your-icu-and-that-the-model-has-been-validated-using-external-datasets"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bias-ensure-the-data-used-for-model-development-by-the-vendor-reflects-the-case-mix-of-your-icu-and-that-the-model-has-been-validated-using-external-datasets"}},[e._v("#")]),e._v(" Bias: ensure the data used for model development by the vendor reflects the case mix of your ICU and that the model has been validated using external datasets.")]),e._v(" "),r("p",[e._v("At their heart ML models are pattern recognition systems and can perform poorly outside the scope of the data used to train them ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR6",target:"_blank",rel:"noopener noreferrer"}},[e._v("6"),r("OutboundLink")],1),e._v("]. They are highly dependent on the characteristics of this training data and vulnerable to any underlying selection biases. Specific patient populations and types of pathology may be under-represented during training but commonly encountered in your practice. Selection bias can reflect the patient population (e.g., age, gender, race), range of pathology (e.g., type and severity), and medical images (e.g., specific equipment, imaging protocol, patient positioning) used during training ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR7",target:"_blank",rel:"noopener noreferrer"}},[e._v("7"),r("OutboundLink")],1),e._v("]. When evaluating an ML system, it is critical to understand the composition of the imaging studies used for training and whether it approximates those at your institution. Models trained on larger and more generalized datasets reduce the risks from bias but cannot entirely eliminate it.")]),e._v(" "),r("h3",{attrs:{id:"model-fragility-ensure-the-vendor-provides-the-parameters-within-which-their-model-should-operate-safely"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#model-fragility-ensure-the-vendor-provides-the-parameters-within-which-their-model-should-operate-safely"}},[e._v("#")]),e._v(" Model fragility: ensure the vendor provides the parameters within which their model should operate safely.")]),e._v(" "),r("p",[e._v("The behavior of an ML system outside the scope of training data can be unpredictable and potentially unsafe ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR8",target:"_blank",rel:"noopener noreferrer"}},[e._v("8"),r("OutboundLink")],1),e._v("]. For example, ML models may fail to detect obvious pathology if the imaging study presented is dissimilar to training data ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR9",target:"_blank",rel:"noopener noreferrer"}},[e._v("9"),r("OutboundLink")],1),e._v("]. More disturbing is that ML models may fail to recognize that they are operating beyond their ‚Äúcomfort zone‚Äù and produce incorrect outputs with high confidence ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR10",target:"_blank",rel:"noopener noreferrer"}},[e._v("10"),r("OutboundLink")],1),e._v("]. Also, ML systems are often trained to distill complex imaging data down to simple binary results: is the pathology present or not? This loss of granularity can result in cases close to the decision boundary being marked as normal even when clinically relevant findings may be present. When considering the implementation of an ML system, it is important to know the parameters within which the model should operate safely, if the model provides a measure of prediction confidence, and how the model will respond to the incomplete or poor-quality imaging studies that are often encountered in the real world.")]),e._v(" "),r("h3",{attrs:{id:"error-prone-behavior-ensure-the-clinical-team-does-not-develop-overdependence-on-the-ml-technology-and-loses-sight-of-its-fallibilities"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#error-prone-behavior-ensure-the-clinical-team-does-not-develop-overdependence-on-the-ml-technology-and-loses-sight-of-its-fallibilities"}},[e._v("#")]),e._v(" Error-prone behavior: ensure the clinical team does not develop overdependence on the ML technology and loses sight of its fallibilities")]),e._v(" "),r("p",[e._v("Computer aids and automation are employed to improve efficiency and reduce error. However, they may actually lead to new and different types of errors ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR11",target:"_blank",rel:"noopener noreferrer"}},[e._v("11"),r("OutboundLink")],1),e._v("]. Individuals may hold beliefs about the superiority of computer systems over human experts ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR12",target:"_blank",rel:"noopener noreferrer"}},[e._v("12"),r("OutboundLink")],1),e._v("] and a consistently reliable system may even appear infallible. Blind trust in computer aids may impair an individual‚Äôs ability to recognize incorrect computer advice which may ultimately result in decision errors ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR11",target:"_blank",rel:"noopener noreferrer"}},[e._v("11"),r("OutboundLink")],1),e._v("]. Furthermore, there is a risk of over-reliance on computer aids particularly in a clinical setting when many concurrent tasks compete for an individual‚Äôs time and attention ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR13",target:"_blank",rel:"noopener noreferrer"}},[e._v("13"),r("OutboundLink")],1),e._v("]. Critical care physicians must be aware that ML models are imperfect and can be used in biased ways; so, human judgment will be necessary in determining how much weight should be given to them in the clinical decision-making process.")]),e._v(" "),r("h2",{attrs:{id:"revisiting-the-clinical-scenario"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#revisiting-the-clinical-scenario"}},[e._v("#")]),e._v(" Revisiting the clinical scenario")]),e._v(" "),r("p",[e._v("Having improved your understanding of AI systems, you realize the usefulness of the proposed system may be overstated. Similar to many current commercial systems targeting medical imaging, the start-up is marketing the product for widespread use but has not validated it on external data or in a full clinical setting ["),r("a",{attrs:{href:"http://61.175.198.136:8083/article/10.1007/s00134-020-06316-8#ref-CR14",target:"_blank",rel:"noopener noreferrer"}},[e._v("14"),r("OutboundLink")],1),e._v("]. Worse, its small training set consists mostly of PA radiographs of non-ICU patients which are notably different from your typical patients. Keenly aware that the value of the system is solely how it behaves in your institution, you insist on more thorough evaluation of the product with local imaging cases prior to further consideration.")]),e._v(" "),r("h3",{attrs:{id:"key-points-for-the-intelligent-use-of-ai-in-medical-imaging"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#key-points-for-the-intelligent-use-of-ai-in-medical-imaging"}},[e._v("#")]),e._v(" Key points for the intelligent use of AI in medical imaging")]),e._v(" "),r("table",[r("thead",[r("tr",[r("th",[e._v("To effectively evaluate a machine learning (ML) system, you should understand how they are created and the common methods used to assess them.")])])]),e._v(" "),r("tbody",[r("tr",[r("td",[e._v("Proper evaluation of an ML system requires you to consider more than the tool‚Äôs accuracy or ROC curve.")])]),e._v(" "),r("tr",[r("td",[e._v("ML systems can be biased in a variety of ways and one that works well in one clinical environment may perform very poorly in another.")])]),e._v(" "),r("tr",[r("td",[e._v("It is common for ML systems to behave unpredictably and potentially dangerously outside the scope of their training data.")])]),e._v(" "),r("tr",[r("td",[e._v("Using an ML system can introduce new types of errors into the clinical decision process.")])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);